{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "18fe76c4",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## MetaData Extraction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "258e0eb6",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "The main aim of this notebook, is to explore and create a metadata table with the track id, name and genre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "38e29b6c",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7f7006c",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "The FMA: A Dataset For Music Analysis provided us with metadata for all their tracks, It was divided into two tables, one had the data of tracks and authors while the other had genres. We read both tables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2882f620",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "tracks = pd.read_csv('./fma_metadata/tracks.csv',low_memory=False)\n",
    "genres = pd.read_csv('./fma_metadata/genres.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8c2ae8c9",
   "metadata": {
    "scrolled": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Unnamed: 0                  NaN\n",
       "album                  comments\n",
       "album.1            date_created\n",
       "album.2           date_released\n",
       "album.3                engineer\n",
       "album.4               favorites\n",
       "album.5                      id\n",
       "album.6             information\n",
       "album.7                 listens\n",
       "album.8                producer\n",
       "album.9                    tags\n",
       "album.10                  title\n",
       "album.11                 tracks\n",
       "album.12                   type\n",
       "artist        active_year_begin\n",
       "artist.1        active_year_end\n",
       "artist.2      associated_labels\n",
       "artist.3                    bio\n",
       "artist.4               comments\n",
       "artist.5           date_created\n",
       "artist.6              favorites\n",
       "artist.7                     id\n",
       "artist.8               latitude\n",
       "artist.9               location\n",
       "artist.10             longitude\n",
       "artist.11               members\n",
       "artist.12                  name\n",
       "artist.13      related_projects\n",
       "artist.14                  tags\n",
       "artist.15               website\n",
       "artist.16        wikipedia_page\n",
       "set                       split\n",
       "set.1                    subset\n",
       "track                  bit_rate\n",
       "track.1                comments\n",
       "track.2                composer\n",
       "track.3            date_created\n",
       "track.4           date_recorded\n",
       "track.5                duration\n",
       "track.6               favorites\n",
       "track.7               genre_top\n",
       "track.8                  genres\n",
       "track.9              genres_all\n",
       "track.10            information\n",
       "track.11               interest\n",
       "track.12          language_code\n",
       "track.13                license\n",
       "track.14                listens\n",
       "track.15               lyricist\n",
       "track.16                 number\n",
       "track.17              publisher\n",
       "track.18                   tags\n",
       "track.19                  title\n",
       "Name: 0, dtype: object"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tracks.iloc[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78e9c705",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "As seen, the tracks columns are not properly present, the actual name of the columns are on row one. But on further investigation it is revealed that the following are the correspondences.\n",
    "\n",
    "Title of song = track.19\n",
    "\n",
    "Id of song = Unnamed: 0\n",
    "\n",
    "Genre = track.7\n",
    "\n",
    "Artist = artist.12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "72f7128b",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "tracknames = os.listdir('./fma_medium_tracks')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83551eb3",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "The above directory represents the songs i.e. the actual audio files, originally the songs , when downloded from FMA is present in multiple folders, after merging them all into a single folder, we read the songs and extract the ids."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d405957c",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "trackIds = []\n",
    "for i in tracknames:\n",
    "    x = i.split('.')\n",
    "    trackIds.append(str(int(x[0])))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab077857",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Once we have extraceted the ids, we create our official meta dataset which contains id, trackname ,genre and trackArtist, while some songs may have multiple genres, we always take the primary genre."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7a05c993",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████| 25000/25000 [03:05<00:00, 135.03it/s]\n"
     ]
    }
   ],
   "source": [
    "tracksMetaData = pd.DataFrame()\n",
    "for idd in tqdm(trackIds):\n",
    "    try:\n",
    "        row = tracks.loc[tracks['Unnamed: 0'] == idd]\n",
    "        df = pd.DataFrame()\n",
    "        df[\"id\"] = [idd]\n",
    "        df[\"trackName\"] = row[\"track.19\"].values\n",
    "        df[\"genre\"] = row[\"track.7\"].values\n",
    "        df[\"trackArtist\"] = row[\"artist.12\"].values\n",
    "        tracksMetaData = pd.concat([tracksMetaData,df])\n",
    "    except:\n",
    "        print(genreNumber)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7223bf7",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Minor Cleanup of duplicates and we see the value counts. We notice that although there are 16 genres, most of them dont have enough number of music, In the future we will drop most of songs from genre that are underrepresented for class balance. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c9c0e29b",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "tracksMetaData = tracksMetaData.drop_duplicates(subset=['id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "967e7b49",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Rock                   7103\n",
       "Electronic             6314\n",
       "Experimental           2251\n",
       "Hip-Hop                2201\n",
       "Folk                   1519\n",
       "Instrumental           1350\n",
       "Pop                    1186\n",
       "International          1018\n",
       "Classical               619\n",
       "Old-Time / Historic     510\n",
       "Jazz                    384\n",
       "Country                 178\n",
       "Soul-RnB                154\n",
       "Spoken                  118\n",
       "Blues                    74\n",
       "Easy Listening           21\n",
       "Name: genre, dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tracksMetaData['genre'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f10eae77",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Saving the csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c4339a27",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "tracksMetaData.to_csv('tracksMetaData.csv',index=False)"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
